{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "4517cb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "from itertools import product\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbf43cd",
   "metadata": {},
   "source": [
    "First let's prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c3ea58ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv('iris.csv')\n",
    "\n",
    "ds.replace('setosa', 1, inplace=True)\n",
    "ds.replace('versicolor', 2, inplace=True)\n",
    "ds.replace('virginica', 3, inplace=True)\n",
    "\n",
    "X = ds[['sepal_length', 'sepal_width', 'petal_length', 'petal_width']].to_numpy()\n",
    "Y = ds['species'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4502a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3bcd71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_rand_ties(a):\n",
    "    \"\"\"\n",
    "        Compute the mode of an array a.\n",
    "        If there are ties for the most frequently occurring\n",
    "        value, break the ties randomly.\n",
    "    \"\"\"\n",
    "    # Compute the unique values in a and their counts\n",
    "    uniq, cnts = np.unique(a, return_counts=True)\n",
    "    max_cnt = np.max(cnts)\n",
    "    \n",
    "    # The array of values which all have count\n",
    "    # equal to the mode\n",
    "    ties = uniq[cnts==max_cnt]\n",
    "    \n",
    "    return np.random.choice(ties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1d4ea523",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nearest_neighbors(X, Y, k):\n",
    "    \"\"\"\n",
    "        Return the k-nearest neighbors classifier\n",
    "        for X and Y.\n",
    "        X: numpy array of input features\n",
    "        Y: numpy array of class labels\n",
    "        k: the number of neighbors\n",
    "    \"\"\"\n",
    "    if isinstance(k, tuple):\n",
    "        k = k[0]\n",
    "    \n",
    "    # The classifier\n",
    "    def f(x):\n",
    "        \n",
    "        # Compute the squared distance between x\n",
    "        # and every row of x\n",
    "        sq_dists = ((x-X)**2).sum(axis=-1)\n",
    "        indices = np.argsort(sq_dists, axis=-1)\n",
    "        \n",
    "        # The rows with the k smallest distances to x\n",
    "        k_smallest = indices[:k]\n",
    "        Y_vals = Y[k_smallest]\n",
    "        \n",
    "        # The classifier returns the mode of class labels\n",
    "        # of the nearest neighbors\n",
    "        return mode_rand_ties(Y_vals)\n",
    "    \n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552bcd7d",
   "metadata": {},
   "source": [
    "Below we perform cross-validation to choose $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "24f44d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_splits(X, Y, num_ch):\n",
    "    \"\"\"\n",
    "        Split the dataset (X, Y) into num_ch random chunks\n",
    "        of equal size (except for possibly the last chunk).\n",
    "        (X, Y): the dataset\n",
    "        num_ch: the number of chunks\n",
    "    \"\"\"\n",
    "    \n",
    "    # Randomly permute (X, Y)\n",
    "    n = len(X)\n",
    "    indices = np.random.permutation(n)\n",
    "    X_perm = X[indices]\n",
    "    Y_perm = Y[indices]\n",
    "    \n",
    "    k = n // num_ch\n",
    "    \n",
    "    # Arrays to hold the chunks\n",
    "    Xs = []\n",
    "    Ys = []\n",
    "    \n",
    "    # Append one chunk at a time\n",
    "    for i in range(num_ch):\n",
    "        if i < num_ch-1:\n",
    "            Xs.append(X_perm[i*k:i*k + k, :])\n",
    "            Ys.append(Y_perm[i*k:i*k + k])\n",
    "        else:\n",
    "            Xs.append(X_perm[i*k:, :])\n",
    "            Ys.append(Y_perm[i*k:])\n",
    "    \n",
    "    return Xs, Ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e6941f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(X, Y, num_ch, model_func):\n",
    "    \"\"\"\n",
    "        Perform n-fold cross-validation where\n",
    "        (X, Y): the dataset\n",
    "        num_ch: the number of folds\n",
    "        model_func: a function which takes X, Y\n",
    "            as input and outputs a classifer function\n",
    "        Returns:\n",
    "            errors: a list of errors for each fold\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    Xs, Ys = create_random_splits(X, Y, num_ch)\n",
    "    \n",
    "    for i in range(num_ch):\n",
    "        X_left_over = np.concatenate(Xs[:i] + Xs[i+1:], axis=0)\n",
    "        Y_left_over = np.concatenate(Ys[:i] + Ys[i+1:], axis=0)\n",
    "        X_ch = Xs[i]\n",
    "        Y_ch = Ys[i]\n",
    "        \n",
    "        model = model_func(X_left_over, Y_left_over)\n",
    "        Y_pred = np.array(list(map(model, X_ch)))\n",
    "        error = (Y_pred != Y_ch).mean()\n",
    "        errors.append(error)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "43f40fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_search(X, Y, num_ch, model_func, param_grid):\n",
    "    \"\"\"\n",
    "        Perform cross-validation with a parameter search.\n",
    "        X: numpy array of input features\n",
    "        Y: numpy array of class labels\n",
    "        num_ch: number of chunks to break the dataset into for cross-validation\n",
    "        model_func: a function that returns a classifier given input features\n",
    "            X, class labels Y, and possibly other parameters\n",
    "        param_grid: a dictionary of parameters and values to test\n",
    "        returns:\n",
    "            out: a list of dictionaries, one for each parameter combination,\n",
    "                displaying the cross-validation errors for that combination\n",
    "                as well as the mean error across all splits\n",
    "    \"\"\"\n",
    "    \n",
    "    # The names of the parameters\n",
    "    param_names = list(param_grid.keys())\n",
    "    \n",
    "    # All possible combinations of the parameter values\n",
    "    param_combos = list(product(*list(param_grid.values())))\n",
    "    \n",
    "    # Input the parameters into the model_func for each combination\n",
    "    params_to_test = [{param_name:param_vals[i] for i, param_name in enumerate(param_names)}\n",
    "                      for param_vals in param_combos]\n",
    "    models_to_test = [partial(model_func, **params) for params in params_to_test]\n",
    "    params_models = list(zip(params_to_test, models_to_test))\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    # Compute the CV errors and mean error for each parameter\n",
    "    # combination and append them to out\n",
    "    for (params, func) in params_models:\n",
    "        errors = cross_validation(X, Y, num_ch, func)\n",
    "        mean_error = np.mean(errors)\n",
    "        out.append({'params': params, 'errors': errors, 'mean_error': mean_error})\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a5ef1",
   "metadata": {},
   "source": [
    "Here are the results of the parameter search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7e5897cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = param_search(X, Y, 5, k_nearest_neighbors, {'k': range(1,51)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "32949471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1\n",
      "Mean error: 0.04000\n",
      "\n",
      "k: 2\n",
      "Mean error: 0.03333\n",
      "\n",
      "k: 3\n",
      "Mean error: 0.03333\n",
      "\n",
      "k: 4\n",
      "Mean error: 0.02667\n",
      "\n",
      "k: 5\n",
      "Mean error: 0.04000\n",
      "\n",
      "k: 6\n",
      "Mean error: 0.03333\n",
      "\n",
      "k: 7\n",
      "Mean error: 0.02000\n",
      "\n",
      "k: 8\n",
      "Mean error: 0.02667\n",
      "\n",
      "k: 9\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 10\n",
      "Mean error: 0.03333\n",
      "\n",
      "k: 11\n",
      "Mean error: 0.02667\n",
      "\n",
      "k: 12\n",
      "Mean error: 0.03333\n",
      "\n",
      "k: 13\n",
      "Mean error: 0.04000\n",
      "\n",
      "k: 14\n",
      "Mean error: 0.02667\n",
      "\n",
      "k: 15\n",
      "Mean error: 0.02667\n",
      "\n",
      "k: 16\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 17\n",
      "Mean error: 0.03333\n",
      "\n",
      "k: 18\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 19\n",
      "Mean error: 0.05333\n",
      "\n",
      "k: 20\n",
      "Mean error: 0.02667\n",
      "\n",
      "k: 21\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 22\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 23\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 24\n",
      "Mean error: 0.07333\n",
      "\n",
      "k: 25\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 26\n",
      "Mean error: 0.05333\n",
      "\n",
      "k: 27\n",
      "Mean error: 0.05333\n",
      "\n",
      "k: 28\n",
      "Mean error: 0.05333\n",
      "\n",
      "k: 29\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 30\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 31\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 32\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 33\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 34\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 35\n",
      "Mean error: 0.04667\n",
      "\n",
      "k: 36\n",
      "Mean error: 0.06667\n",
      "\n",
      "k: 37\n",
      "Mean error: 0.07333\n",
      "\n",
      "k: 38\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 39\n",
      "Mean error: 0.06667\n",
      "\n",
      "k: 40\n",
      "Mean error: 0.05333\n",
      "\n",
      "k: 41\n",
      "Mean error: 0.08000\n",
      "\n",
      "k: 42\n",
      "Mean error: 0.06667\n",
      "\n",
      "k: 43\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 44\n",
      "Mean error: 0.08667\n",
      "\n",
      "k: 45\n",
      "Mean error: 0.06667\n",
      "\n",
      "k: 46\n",
      "Mean error: 0.08000\n",
      "\n",
      "k: 47\n",
      "Mean error: 0.05333\n",
      "\n",
      "k: 48\n",
      "Mean error: 0.08000\n",
      "\n",
      "k: 49\n",
      "Mean error: 0.06000\n",
      "\n",
      "k: 50\n",
      "Mean error: 0.10667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in out:\n",
    "    print(f\"k: {d['params']['k']}\")\n",
    "    print(f\"Mean error: {d['mean_error']:.5f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77484a1a",
   "metadata": {},
   "source": [
    "$k=11$ gives the lowest mean error, $0.02667$, for cross validation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
