{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9981a25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a8e3d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecb4010",
   "metadata": {},
   "source": [
    "Part (d)\n",
    "--"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c9e82",
   "metadata": {},
   "source": [
    "First let's compute the mean squared error for the plug-in estimator $\\tilde \\tau$ analytically. We have\n",
    "$$\\tilde \\tau = \\frac{1}{n} \\sum X_i = \\overline{X_n}.$$\n",
    "So\n",
    "$$\\mathbb V(\\tilde \\tau) = \\frac{1}{n^2} \\sum \\mathbb V(X_i) = \\frac{1}{12n}(b-a)^2.$$ Moreover, $\\mathbb E(\\tilde \\tau) = \\frac{1}{n} \\sum \\mathbb E(X_i) = \\frac{a+b}{2}$ so $\\tilde\\tau$ is unbiased. Thus its mean squared error is $(b-a)^2/(12n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df061a1c",
   "metadata": {},
   "source": [
    "Let's calculate the mean squared error for the specified values of $a,b,n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7932b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, n = 1, 3, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9a3b0cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = (a + b) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "26b1788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = (b - a)**2 / (12 * n)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ab364a",
   "metadata": {},
   "source": [
    "Now we bootstrap to estimate the mean squared error of the maximum likelihood estimator $\\hat \\tau = (\\max(X_i) + \\min(X_i))/2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e31e7dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.uniform(low=a, high=b, size=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b70d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = int(1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d00554d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_boot = np.empty(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e1872408",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(B):\n",
    "    X_star = np.random.choice(X, size=n, replace=True)\n",
    "    T_boot[i] = (np.min(X_star) + np.max(X_star)) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f8b4c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "EST_MSE = np.mean((T_boot - tau)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "fd05398d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error of plug-in estimator: 0.03333\n",
      "Estimated mean squared error of MLE: 0.01177\n"
     ]
    }
   ],
   "source": [
    "print('Mean squared error of plug-in estimator: {:.5f}'.format(MSE))\n",
    "print('Estimated mean squared error of MLE: {:.5f}'.format(EST_MSE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7085d0b8",
   "metadata": {},
   "source": [
    "Thus the maximum likelihood estimator appears to have a lower mean squared error than the plug-in estimator."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearn",
   "language": "python",
   "name": "deeplearn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
